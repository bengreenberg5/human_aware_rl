{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f02f04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import dill\n",
    "import logging\n",
    "import os\n",
    "from pprint import pprint\n",
    "\n",
    "from human_aware_rl.rllib.rllib import gen_trainer_from_params, load_agent, OvercookedMultiAgent\n",
    "from human_aware_rl.ppo.ppo_rllib_client import my_config\n",
    "from overcooked_ai_py.agents.benchmarking import AgentEvaluator\n",
    "from overcooked_ai_py.mdp.actions import Action\n",
    "from overcooked_ai_py.mdp.layout_generator import DEFAILT_PARAMS_SCHEDULE_FN, LayoutGenerator, MDPParamsGenerator\n",
    "\n",
    "RAY_DIRECTORY = os.path.expanduser(\"~/ray_results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f10acd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkpoint_path(run_name, seed=0, checkpoint_num=1):\n",
    "    run_dir = sorted([r for r in os.listdir(RAY_DIRECTORY) if f\"{run_name}_{seed}\" in r])[0]\n",
    "    cp_path = f\"{RAY_DIRECTORY}/{run_dir}/checkpoint_{checkpoint_num}/checkpoint-{checkpoint_num}\"\n",
    "    return cp_path\n",
    "\n",
    "def load_params(run_name, seed=0):\n",
    "    cp_path = checkpoint_path(\"10k\", 1024)\n",
    "    params_path = \"/\".join(cp_path.split(\"/\")[:-1]) + \"/config.pkl\"\n",
    "    params = dill.load(open(params_path, \"rb\"))\n",
    "    return params\n",
    "\n",
    "def load_env(run_name, seed=0):\n",
    "    params = load_params(run_name, seed)\n",
    "    return OvercookedMultiAgent.from_config(params[\"environment_params\"])\n",
    "\n",
    "def load_agents(run_name, seeds, checkpoint_num):        \n",
    "    agents = {}\n",
    "    for seed in seeds:\n",
    "        agents[seed] = load_agent(\n",
    "            checkpoint_path(run_name, seed=seed, checkpoint_num=checkpoint_num), \n",
    "            policy_id=\"ppo\", \n",
    "            agent_index=-1  # set to 0 or 1 when initializing episode\n",
    "        )\n",
    "    return agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8bbd7dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_play(mdp, agent_0, agent_1, num_games=100, rnd_obj_prob_thresh=0.0):\n",
    "    params = {\n",
    "        'horizon': 400, \n",
    "        'mlam_params': {\n",
    "            'start_orientations': False,\n",
    "            'wait_allowed': False,\n",
    "            'counter_goals': [],\n",
    "            'counter_drop': [],\n",
    "            'counter_pickup': [],\n",
    "            'same_motion_goals': True\n",
    "        }\n",
    "    }\n",
    "    start_state_fn = mdp.get_random_start_state_fn(random_start_pos=False, rnd_obj_prob_thresh=rnd_obj_prob_thresh)\n",
    "    \n",
    "    trajs_0_0 = AgentEvaluator.from_mdp(mdp, params).get_agent_pair_trajs(\n",
    "        a0=agent_0, num_games=num_games, start_state_fn=start_state_fn\n",
    "    )\n",
    "    print(f\"agent 0 self-play: {trajs_0_0[0]['ep_returns'].mean()}\")\n",
    "\n",
    "    trajs_1_1 = AgentEvaluator.from_mdp(mdp, params).get_agent_pair_trajs(\n",
    "        a0=agent_1, num_games=num_games, start_state_fn=start_state_fn\n",
    "    )\n",
    "    print(f\"agent 1 self-play: {trajs_1_1[0]['ep_returns'].mean()}\")\n",
    "\n",
    "    trajs_0_1 = AgentEvaluator.from_mdp(mdp, params).get_agent_pair_trajs(\n",
    "        a0=agent_0, a1=agent_1, num_games=num_games, start_state_fn=start_state_fn\n",
    "    )\n",
    "    print(f\"cross-play: {trajs_0_1[0]['ep_returns'].mean()}\")\n",
    "    \n",
    "    return trajs_0_0, trajs_1_1, trajs_0_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aad10450",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-27 12:18:49,417\tINFO resource_spec.py:212 -- Starting Ray with 14.26 GiB memory available for workers and up to 7.14 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n",
      "2021-07-27 12:18:49,984\tINFO trainer.py:421 -- Tip: set 'eager': true or the --eager flag to enable TensorFlow eager execution\n",
      "2021-07-27 12:18:50,051\tINFO trainer.py:580 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "/home/anchorwatt/miniconda3/envs/harl/lib/python3.7/site-packages/tensorflow/python/keras/legacy_tf_layers/core.py:329: UserWarning: `tf.layers.flatten` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Flatten` instead.\n",
      "  warnings.warn('`tf.layers.flatten` is deprecated and '\n",
      "/home/anchorwatt/miniconda3/envs/harl/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer_v1.py:1692: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n",
      "2021-07-27 12:18:57,726\tINFO trainable.py:217 -- Getting current IP.\n",
      "2021-07-27 12:18:57,792\tINFO trainable.py:217 -- Getting current IP.\n",
      "2021-07-27 12:18:57,793\tINFO trainable.py:423 -- Restored on 192.168.1.233 from checkpoint: /home/anchorwatt/ray_results/10k_1024_2021-07-17_19-09-08lxahhjhf/checkpoint_6601/checkpoint-6601\n",
      "2021-07-27 12:18:57,793\tINFO trainable.py:430 -- Current state after restoring: {'_iteration': 6601, '_timesteps_total': 79212000, '_time_total': 92236.27584052086, '_episodes_total': 198030}\n",
      "/home/anchorwatt/miniconda3/envs/harl/lib/python3.7/site-packages/tensorflow/python/keras/legacy_tf_layers/core.py:329: UserWarning: `tf.layers.flatten` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Flatten` instead.\n",
      "  warnings.warn('`tf.layers.flatten` is deprecated and '\n",
      "/home/anchorwatt/miniconda3/envs/harl/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer_v1.py:1692: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n",
      "/home/anchorwatt/miniconda3/envs/harl/lib/python3.7/site-packages/tensorflow/python/keras/legacy_tf_layers/core.py:329: UserWarning: `tf.layers.flatten` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Flatten` instead.\n",
      "  warnings.warn('`tf.layers.flatten` is deprecated and '\n",
      "/home/anchorwatt/miniconda3/envs/harl/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer_v1.py:1692: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n",
      "/home/anchorwatt/miniconda3/envs/harl/lib/python3.7/site-packages/tensorflow/python/keras/legacy_tf_layers/core.py:329: UserWarning: `tf.layers.flatten` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Flatten` instead.\n",
      "  warnings.warn('`tf.layers.flatten` is deprecated and '\n",
      "/home/anchorwatt/miniconda3/envs/harl/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer_v1.py:1692: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n",
      "/home/anchorwatt/miniconda3/envs/harl/lib/python3.7/site-packages/tensorflow/python/keras/legacy_tf_layers/core.py:329: UserWarning: `tf.layers.flatten` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Flatten` instead.\n",
      "  warnings.warn('`tf.layers.flatten` is deprecated and '\n",
      "/home/anchorwatt/miniconda3/envs/harl/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer_v1.py:1692: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n",
      "2021-07-27 12:19:01,322\tINFO trainable.py:217 -- Getting current IP.\n",
      "2021-07-27 12:19:01,382\tINFO trainable.py:217 -- Getting current IP.\n",
      "2021-07-27 12:19:01,383\tINFO trainable.py:423 -- Restored on 192.168.1.233 from checkpoint: /home/anchorwatt/ray_results/mod_1024_2021-07-22_02-34-46zpk6i07h/checkpoint_1426/checkpoint-1426\n",
      "2021-07-27 12:19:01,383\tINFO trainable.py:430 -- Current state after restoring: {'_iteration': 1426, '_timesteps_total': 17112000, '_time_total': 26294.825267076492, '_episodes_total': 42780}\n",
      "Avg rew: 62.00 (std: 22.72, se: 7.18); avg len: 400.00; : 100%|█████████████████████████| 10/10 [00:12<00:00,  1.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping trajectory consistency checking because MDP was recognized as variable. Trajectory consistency checking is not yet supported for variable MDPs.\n",
      "agent 0 self-play: 62.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg rew: 0.00 (std: 0.00, se: 0.00); avg len: 400.00; : 100%|███████████████████████████| 10/10 [00:12<00:00,  1.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping trajectory consistency checking because MDP was recognized as variable. Trajectory consistency checking is not yet supported for variable MDPs.\n",
      "agent 1 self-play: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg rew: 32.00 (std: 16.00, se: 5.06); avg len: 400.00; : 100%|█████████████████████████| 10/10 [00:12<00:00,  1.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping trajectory consistency checking because MDP was recognized as variable. Trajectory consistency checking is not yet supported for variable MDPs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg rew: 32.00 (std: 20.40, se: 6.45); avg len: 400.00; : 100%|█████████████████████████| 10/10 [00:12<00:00,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping trajectory consistency checking because MDP was recognized as variable. Trajectory consistency checking is not yet supported for variable MDPs.\n",
      "cross-play: 32.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# mdp = LayoutGenerator(MDPParamsGenerator(DEFAILT_PARAMS_SCHEDULE_FN)).generate_padded_mdp()\n",
    "mdp = load_env(\"10k\", 1024).base_env.mdp\n",
    "path_0 = checkpoint_path(\"10k\", seed=1024, checkpoint_num=6601)\n",
    "path_1 = checkpoint_path(\"mod\", seed=1024, checkpoint_num=1426)\n",
    "num_games = 10\n",
    "rnd_obj_prob_thresh = 0.0\n",
    "\n",
    "agent_0 = load_agent(path_0, policy_id=\"ppo\", agent_index=0)\n",
    "agent_1 = load_agent(path_1, policy_id=\"ppo\", agent_index=1)\n",
    "trajs_0_0, trajs_1_1, trajs_0_1 = cross_play(mdp, agent_0, agent_1, num_games, rnd_obj_prob_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cdfd8428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 1.9.5\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb470e20ca7a452d8f4be36d6b439583",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='timestep', max=399), Output()), _dom_classes=('widget-in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from overcooked_ai_py.visualization.state_visualizer import *\n",
    "\n",
    "StateVisualizer().display_rendered_trajectory(\n",
    "    trajs_1_1[0], img_directory_path=\"/home/anchorwatt/traj_0_0\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a4320f8",
   "metadata": {},
   "outputs": [
    {
     "ename": "PicklingError",
     "evalue": "Can't pickle <class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>: attribute lookup PPOTFPolicy on ray.rllib.policy.tf_policy_template failed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPicklingError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_574945/3140987897.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent_0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mPicklingError\u001b[0m: Can't pickle <class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>: attribute lookup PPOTFPolicy on ray.rllib.policy.tf_policy_template failed"
     ]
    }
   ],
   "source": [
    "pickle.dumps(agent_0.policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23b14202",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<human_aware_rl.rllib.rllib.RlLibAgent at 0x7f7f7475dad0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ALSA lib pcm.c:8545:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8545:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8545:(snd_pcm_recover) underrun occurred\n"
     ]
    }
   ],
   "source": [
    "agent_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1472aaf8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
